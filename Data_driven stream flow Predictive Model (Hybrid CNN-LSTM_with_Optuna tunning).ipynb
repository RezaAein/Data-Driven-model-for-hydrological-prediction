{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna --quiet"
      ],
      "metadata": {
        "id": "oTJOgDTXgvIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna-integration --quiet"
      ],
      "metadata": {
        "id": "S3323sOd_4th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import optuna\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,Conv1D, MaxPooling1D, Flatten, Dense, Dropout, InputLayer\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from optuna.integration import TFKerasPruningCallback"
      ],
      "metadata": {
        "id": "n7fkZHVJ_sr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "Pwc0ZsCuHNdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df_original= pd.read_excel('Total.xlsx')\n",
        "print(df_original.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUh7HiJ7IUls",
        "outputId": "7db75a77-7a2b-40e6-e466-7ec420c9fa6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Date  Max Temperature  Min Temperature  Precipitation      Wind  \\\n",
            "0 1981-03-21           32.129           15.476       0.000000  2.323745   \n",
            "1 1981-03-22           30.684           19.719       0.607683  2.686932   \n",
            "2 1981-03-23           32.564           19.376       4.067518  2.694658   \n",
            "3 1981-03-24           33.151           23.626       0.000000  5.599542   \n",
            "4 1981-03-25           30.615           24.187       0.000000  3.765550   \n",
            "\n",
            "   Relative Humidity      Solar  tabkhir  debi  \n",
            "0           0.324832  22.450215      2.9  86.0  \n",
            "1           0.379659  21.654897      2.6  75.6  \n",
            "2           0.417122  19.871775      2.2  70.0  \n",
            "3           0.227993  15.473473      2.3  64.4  \n",
            "4           0.280895   9.735983      1.1  69.2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values\n",
        "df_original['debi'] = df_original['debi'].fillna(df_original['debi'].mean())\n",
        "df_original['tabkhir'] = df_original['tabkhir'].fillna(df_original['tabkhir'].mean())\n",
        "\n",
        "# Convert 'Date' column to datetime and set as index\n",
        "df_original.index = pd.to_datetime(df_original['Date'], format='%d.%m.%Y %H:%M:%S')\n",
        "df_original = df_original.drop(columns=['Date'])  # Drop the original 'Date' column\n",
        "\n",
        "df=df_original.copy()"
      ],
      "metadata": {
        "id": "nksY1dPSIXQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZx3Rb8NSioD",
        "outputId": "d1c0249d-c165-4ebc-d608-5824796db12f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Max Temperature  Min Temperature  Precipitation      Wind  \\\n",
            "Date                                                                    \n",
            "1981-03-21           32.129           15.476       0.000000  2.323745   \n",
            "1981-03-22           30.684           19.719       0.607683  2.686932   \n",
            "1981-03-23           32.564           19.376       4.067518  2.694658   \n",
            "1981-03-24           33.151           23.626       0.000000  5.599542   \n",
            "1981-03-25           30.615           24.187       0.000000  3.765550   \n",
            "\n",
            "            Relative Humidity      Solar  tabkhir  debi  \n",
            "Date                                                     \n",
            "1981-03-21           0.324832  22.450215      2.9  86.0  \n",
            "1981-03-22           0.379659  21.654897      2.6  75.6  \n",
            "1981-03-23           0.417122  19.871775      2.2  70.0  \n",
            "1981-03-24           0.227993  15.473473      2.3  64.4  \n",
            "1981-03-25           0.280895   9.735983      1.1  69.2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering\n",
        "def create_lag_features(df, target_col, lags):\n",
        "    for lag in lags:\n",
        "        df[f'{target_col}_lag_{lag}'] = df[target_col].shift(lag)\n",
        "    return df.dropna()\n",
        "\n",
        "def create_rolling_features(df, target_col, window_sizes):\n",
        "    for window in window_sizes:\n",
        "        df[f'{target_col}_rolling_mean_{window}'] = df[target_col].rolling(window=window).mean()\n",
        "        df[f'{target_col}_rolling_std_{window}'] = df[target_col].rolling(window=window).std()\n",
        "    return df.dropna()\n",
        "\n",
        "def create_temporal_features(df):\n",
        "    df['day_of_week'] = df.index.dayofweek\n",
        "    df['month'] = df.index.month\n",
        "    df['season'] = (df.index.month % 12 + 3) // 3  # 1: Winter, 2: Spring, 3: Summer, 4: Fall\n",
        "    return df\n",
        "\n",
        "def create_domain_features(df):\n",
        "    df['cumulative_precipitation'] = df['Precipitation'].cumsum()\n",
        "    df['temperature_anomaly'] = df['Max Temperature'] - df['Max Temperature'].rolling(window=30).mean()\n",
        "    return df"
      ],
      "metadata": {
        "id": "JF8Q5sO1HQ2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply feature engineering\n",
        "# df = create_lag_features(df, 'debi', lags=[1, 2, 3, 7, 14])\n",
        "# df = create_rolling_features(df, 'debi', window_sizes=[3, 7, 14])\n",
        "# df = create_temporal_features(df)\n",
        "# df = create_domain_features(df)\n",
        "# df = df.dropna()"
      ],
      "metadata": {
        "id": "DIhmbmvsfjS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data\n",
        "for col in df.columns:\n",
        "    df[col] = df[col] / df[col].max()\n"
      ],
      "metadata": {
        "id": "u9d7IdULHWQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI7tSNTNVV8O",
        "outputId": "b8afd4f6-0e05-4e6a-a9df-89d73cf96295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Max Temperature  Min Temperature  Precipitation      Wind  \\\n",
            "Date                                                                    \n",
            "1981-03-21         0.635199         0.418950       0.000000  0.255033   \n",
            "1981-03-22         0.606631         0.533812       0.007118  0.294893   \n",
            "1981-03-23         0.643799         0.524526       0.047643  0.295741   \n",
            "1981-03-24         0.655404         0.639578       0.000000  0.614554   \n",
            "1981-03-25         0.605267         0.654764       0.000000  0.413272   \n",
            "\n",
            "            Relative Humidity     Solar   tabkhir      debi  \n",
            "Date                                                         \n",
            "1981-03-21           0.356202  0.712268  0.150259  0.076992  \n",
            "1981-03-22           0.416324  0.687035  0.134715  0.067681  \n",
            "1981-03-23           0.457405  0.630463  0.113990  0.062668  \n",
            "1981-03-24           0.250011  0.490920  0.119171  0.057654  \n",
            "1981-03-25           0.308022  0.308889  0.056995  0.061952  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into features and target\n",
        "X = df.drop(columns=['debi'])\n",
        "y = df['debi']"
      ],
      "metadata": {
        "id": "G3MtQWT1HZyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences for CNN_LSTM\n",
        "def df_to_X_y(df, window_size=12):\n",
        "    df_as_np = df.to_numpy()\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(df_as_np) - window_size):\n",
        "        row = [r for r in df_as_np[i:i + window_size]]\n",
        "        X.append(row)\n",
        "        label = df_as_np[i + window_size][-1]  # Assuming 'debi' is the last column\n",
        "        y.append(label)\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "_E0bbzCYHfYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplly sequencing for CNN-Lstm\n",
        "window_size = 30\n",
        "X1, y1 = df_to_X_y(df, window_size)"
      ],
      "metadata": {
        "id": "ik2bG61vHgrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training, validation, and test sets\n",
        "train_size = int(0.8 * X1.shape[0])\n",
        "val_size = int(0.10 * X1.shape[0])\n",
        "test_size = X1.shape[0] - train_size - val_size\n",
        "\n",
        "X_train1, y_train1 = X1[:train_size], y1[:train_size]\n",
        "X_val1, y_val1 = X1[train_size:train_size + val_size], y1[train_size:train_size + val_size]\n",
        "X_test1, y_test1 = X1[train_size + val_size:], y1[train_size + val_size:]"
      ],
      "metadata": {
        "id": "T7GVE8qDHoer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Optuna multi-processed approach for hyper parameter tuning:\n",
        "# The model is tailored with CNN-LSTM\n",
        "def objective(trial):\n",
        "    # Define hyperparameters\n",
        "    num_filters = trial.suggest_int('num_filters', 32, 256, step=32)  # Number of filters\n",
        "    kernel_size = trial.suggest_int('kernel_size', 2, 5)  # Size of the convolution window\n",
        "    pool_size = trial.suggest_int('pool_size', 2, 4)  # Pooling window size\n",
        "    lstm_units = trial.suggest_int('lstm_units', 64, 256, step=64)\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5, step=0.1)\n",
        "    num_dense_layers = trial.suggest_int('num_dense_layers', 1, 3)\n",
        "    dense_units = trial.suggest_int('dense_units', 64, 256, step=64)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
        "\n",
        "    # Build the model\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer((X_train1.shape[1], X_train1.shape[2])))\n",
        "\n",
        "    # CNN layers\n",
        "    model.add(Conv1D(filters=num_filters, kernel_size=kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=pool_size))\n",
        "    model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    # LSTM for Sequence Processing\n",
        "    model.add(LSTM(units=lstm_units, return_sequences=False))\n",
        "    model.add(Dropout(rate=dropout_rate))  # Second Dropout after LSTM\n",
        "\n",
        "    for _ in range(num_dense_layers):\n",
        "        model.add(Dense(units=dense_units, activation='relu'))\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss=MeanSquaredError(),\n",
        "                  metrics=[RootMeanSquaredError()])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train1, y_train1,\n",
        "        validation_data=(X_val1, y_val1),\n",
        "        epochs=100,\n",
        "        callbacks=[\n",
        "            EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "            TFKerasPruningCallback(trial, 'val_loss')\n",
        "        ],\n",
        "        verbose=0  # Suppresses training logs for better performance\n",
        "    )\n",
        "\n",
        "    # Save the model after training (for later use)\n",
        "    model.save(f\"best_CNNLSTM_model_trial_{trial.number}.keras\")\n",
        "\n",
        "    # Return both the best validation loss and the entire history, as well as\n",
        "    trial.set_user_attr(\"history\", history.history)\n",
        "    return min(history.history['val_loss'])"
      ],
      "metadata": {
        "id": "gtsGFO5Ce0Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "print(\"CPU Cores Available:\", multiprocessing.cpu_count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPdontQICdxC",
        "outputId": "187031c7-6435-4b0e-f28f-ca8d886e93aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Cores Available: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import tensorflow as tf\n",
        "#tf.config.set_visible_devices(tf.config.list_physical_devices('GPU')[0], 'GPU')"
      ],
      "metadata": {
        "id": "3p0pBGY4CmXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optuna.samplers import TPESampler"
      ],
      "metadata": {
        "id": "dT_OCrIH-Tw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Optuna study\n",
        "study = optuna.create_study(\n",
        "    direction='minimize',  # Minimize validation loss\n",
        "    sampler=TPESampler(),  # Use TPE (Tree-structured Parzen Estimator) for efficient sampling\n",
        "    pruner=optuna.pruners.MedianPruner()  # Prune unpromising trials\n",
        ")\n",
        "\n",
        "#study.optimize(objective, n_trials=10, n_jobs=-1)  # Use all available cores n_jobs=-1 (for using multicpu)\n",
        "study.optimize(objective, n_trials=200, n_jobs=-1)  # Use all available cores n_jobs=1 (for using GPU)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "t2qYzaUb7zra",
        "outputId": "ea7a6f12-9081-4194-d070-32f1177a7469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-20 07:37:08,397] A new study created in memory with name: no-name-2c2713d2-6857-46db-85d6-710d92df95ab\n",
            "[I 2025-02-20 07:39:35,437] Trial 1 finished with value: 0.002517451997846365 and parameters: {'num_filters': 160, 'kernel_size': 5, 'pool_size': 3, 'lstm_units': 256, 'dropout_rate': 0.30000000000000004, 'num_dense_layers': 2, 'dense_units': 256, 'learning_rate': 0.0011663010194205299}. Best is trial 1 with value: 0.002517451997846365.\n",
            "[I 2025-02-20 07:40:30,039] Trial 0 finished with value: 0.002521760994568467 and parameters: {'num_filters': 160, 'kernel_size': 5, 'pool_size': 3, 'lstm_units': 192, 'dropout_rate': 0.5, 'num_dense_layers': 2, 'dense_units': 192, 'learning_rate': 0.0004760362530129803}. Best is trial 1 with value: 0.002517451997846365.\n",
            "[I 2025-02-20 07:41:37,305] Trial 2 finished with value: 0.002602740889415145 and parameters: {'num_filters': 128, 'kernel_size': 5, 'pool_size': 4, 'lstm_units': 256, 'dropout_rate': 0.4, 'num_dense_layers': 3, 'dense_units': 256, 'learning_rate': 0.0062527868700421145}. Best is trial 1 with value: 0.002517451997846365.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                         \u001b[0mcompleted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_when\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFIRST_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                         \u001b[0;31m# Raise if exception occurred in executing the completed futures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m     \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-ccff63e233da>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#study.optimize(objective, n_trials=10, n_jobs=-1)  # Use all available cores n_jobs=-1 (for using multicpu)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use all available cores n_jobs=1 (for using GPU)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mfutures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mn_submitted_trials\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", study.best_params)"
      ],
      "metadata": {
        "id": "wJsyAqhx8Lef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the best model\n",
        "best_trial = study.best_trial\n",
        "best_history = best_trial.user_attrs[\"history\"]  # Retrieve stored history\n",
        "best_model = tf.keras.models.load_model(f\"best_model_trial_{best_trial.number}.keras\") # retrive best model"
      ],
      "metadata": {
        "id": "r9HiqPVG8NaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna.visualization as ov\n",
        "\n",
        "# Plot optimization history (to show loss decreasing globally)\n",
        "fig = ov.plot_optimization_history(study)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "D5uAUfodJDG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot importance of each hyper parameters\n",
        "fig = ov.plot_param_importances(study)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "CrX4q-qSJOze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot paralle coordination of parameters\n",
        "fig = ov.plot_parallel_coordinate(study)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "D42AqrtbJTim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot architecture of the best model\n",
        "from keras.utils import plot_model\n",
        "\n",
        "plot_model(best_model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "B0jTQg3udSxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "def evaluate_model(model, X, y):\n",
        "    predictions = model.predict(X).flatten()\n",
        "    mse = mean_squared_error(y, predictions)\n",
        "    mae = mean_absolute_error(y, predictions)\n",
        "    r2 = r2_score(y, predictions)\n",
        "    mape = np.mean(np.abs((y_test1 - predictions) / y_test1)) * 100  # mean absolute percentage error\n",
        "    return mse, mae, r2, mape\n",
        "\n",
        "mse, mae, r2 ,mape= evaluate_model(best_model, X_test1, y_test1)\n",
        "print(f'MSE: {mse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.2f}% ,RÂ²: {r2:.4f}')"
      ],
      "metadata": {
        "id": "h6xRhV-3PPJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(best_history['loss'], label='Training Loss', linestyle='-', marker='o')\n",
        "plt.plot(best_history['val_loss'], label='Validation Loss', linestyle='--', marker='s')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "de1v0Kd9PeLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(best_history['loss'], label='Training Loss')\n",
        "plt.plot(best_history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.yscale('log')  # Use log scale for better visualization\n",
        "plt.title('Training vs Validation Loss (Log Scale)')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RKis_GSFdlEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reverse normalization\n",
        "def reverse_normalization(predictions, original_data, feature_index):\n",
        "    max_value = original_data.iloc[:, feature_index].max()\n",
        "    real_predictions = predictions * max_value\n",
        "    return real_predictions\n",
        "\n",
        "test_predictions = best_model.predict(X_test1).flatten()\n",
        "real_predictions = reverse_normalization(test_predictions, df_original, feature_index=-1)\n",
        "real_actuals = reverse_normalization(y_test1, df_original, feature_index=-1)"
      ],
      "metadata": {
        "id": "LI0LS4TdPsRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot actual vs. predicted values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(real_actuals, label='Actual Values')\n",
        "plt.plot(real_predictions, label='Predicted Values', linestyle='--')\n",
        "plt.xlabel('Time Steps')\n",
        "plt.ylabel('Debi (Real Scale)')\n",
        "plt.title('Actual vs Predicted (Real Scale)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n03iPKhWP8Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_normalization2(predictions, original_data, feature_index):\n",
        "\n",
        "    max_value = original_data.iloc[:, feature_index].max()\n",
        "    real_predictions = np.array(predictions) * max_value  # Convert to NumPy array before multiplication\n",
        "    return real_predictions"
      ],
      "metadata": {
        "id": "vktE7ymzQDLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forecast future values\n",
        "def forecast_future(model, initial_sequence, future_steps):\n",
        "    future_predictions = []\n",
        "    current_sequence = initial_sequence.copy()\n",
        "\n",
        "    for _ in range(future_steps):\n",
        "        next_value = model.predict(current_sequence)[0][0]\n",
        "        future_predictions.append(next_value)\n",
        "        current_sequence = np.roll(current_sequence, shift=-1, axis=1)\n",
        "        current_sequence[0, -1, -1] = next_value  # Assuming the target is the last feature\n",
        "\n",
        "    return future_predictions\n",
        "\n",
        "future_steps = 30\n",
        "initial_sequence = X_test1[-1:]\n",
        "future_predictions = forecast_future(best_model, initial_sequence, future_steps)\n",
        "future_predictions = reverse_normalization2(future_predictions, df_original, feature_index=-1)"
      ],
      "metadata": {
        "id": "jM5D2WTBQJt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot future forecast\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(np.arange(len(real_actuals)), real_actuals, label='Historical Data')\n",
        "plt.plot(real_predictions, label='Predicted Values', linestyle='--', color='orange')\n",
        "plt.plot(np.arange(len(real_actuals), len(real_actuals) + future_steps), future_predictions, label='Forecast', linestyle='--', color='r')\n",
        "plt.xlabel('Time Steps')\n",
        "plt.ylabel('Debi (Real Scale)')\n",
        "plt.title(f'Test MSE = {mse:.6f}')\n",
        "#plt.title('Actual vs Predicted (Real Scale) + Future Forecast ')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5ty5tqfuQP9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# another technique fr future forecasting to avoid compouniding errors:\n",
        "\n",
        "def forecast_future(model, initial_sequence, future_steps, window_size=30):\n",
        "    future_predictions = []\n",
        "    current_sequence = initial_sequence.copy()\n",
        "\n",
        "    for _ in range(future_steps):\n",
        "        # Predict the next value based on the current sequence\n",
        "        next_value = model.predict(current_sequence)[0][0]\n",
        "\n",
        "        # Append the predicted value to the future predictions\n",
        "        future_predictions.append(next_value)\n",
        "\n",
        "        # Instead of rolling the sequence, keep the last window of original data\n",
        "        current_sequence = np.roll(current_sequence, shift=-1, axis=1)\n",
        "        current_sequence[0, -1, -1] = next_value  # Keep using the predicted value without adding to the sequence\n",
        "\n",
        "    return future_predictions\n"
      ],
      "metadata": {
        "id": "UKEfqV-ld1Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forecast future steps\n",
        "future_steps = 30\n",
        "initial_sequence = X_test1[-1:]  # Last sequence in test data\n",
        "future_predictions = forecast_future(best_model, initial_sequence, future_steps)\n",
        "\n",
        "# Plotting future forecast\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(np.arange(len(real_actuals)), real_actuals, label='Historical Data')\n",
        "plt.plot(real_predictions, label='Predicted Values', linestyle='--', color='orange')\n",
        "plt.plot(np.arange(len(real_actuals), len(real_actuals) + future_steps), future_predictions, label='Forecast', linestyle='--', color='r')\n",
        "plt.xlabel('Time Steps')\n",
        "plt.ylabel('Debi (Real Scale)')\n",
        "plt.title(f'Test MSE = {mse:.6f}')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-fIPEqDyj9Nd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}